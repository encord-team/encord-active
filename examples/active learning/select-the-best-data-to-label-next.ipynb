{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Select the best data to label next with Active Learning\n",
    "\n",
    "**Prerequisites**:\n",
    "You need to have encord-active [installed](https://docs.encord.com/active/docs/installation).\n",
    "\n",
    "This notebook shows you how to plug your model in Encord Active and use it to select the best data to label next in the MNIST sandbox project.\n",
    "\n",
    "It follows four steps:\n",
    "1. Download the MNIST sandbox project.\n",
    "2. Train a model with labeled data from the project.\n",
    "3. Run Entropy acquisition function powered by the model to score project data.\n",
    "4. Rank and sample unlabelled data to label next.\n",
    "   1. \\[Optional\\] Visualize sampled data and scores.\n",
    "\n",
    "**Note**: As the MNIST dataset is completely labeled from the start, we train the model only on a subset of the project data and use that knowledge to infer what data to label next in the complement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the MNIST sandbox project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from encord_active.lib.project.project_file_structure import ProjectFileStructure\n",
    "from encord_active.lib.project.sandbox_projects import fetch_prebuilt_project\n",
    "\n",
    "project_name = \"[open-source][test]-mnist-dataset\"\n",
    "\n",
    "# Choose where to store the project\n",
    "project_path = Path.cwd() / project_name\n",
    "\n",
    "# Download the project\n",
    "fetch_prebuilt_project(project_name, project_path)\n",
    "\n",
    "project_fs = ProjectFileStructure(project_path)\n",
    "\n",
    "class_name = \"digit\" # name of the text classification to work with\n",
    "subset_size = 5000 # amount of data samples used to train the model\n",
    "batch_size_to_label = 100 # amount of data samples selected to label next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model with labeled data from the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from encord_active.lib.common.active_learning import get_data, get_data_hashes_from_project\n",
    "from encord_active.lib.metrics.acquisition_functions import SKLearnModelWrapper\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 500)\n",
    "\n",
    "# Wrap the model to interface its behaviour with the one expected in the acquisition function\n",
    "w_model = SKLearnModelWrapper(forest)\n",
    "\n",
    "# Read and transform the project data with `SKLearnModelWrapper.prepare_data()` function\n",
    "data_hashes = get_data_hashes_from_project(project_fs, subset_size)\n",
    "X, y = get_data(project_fs, w_model, data_hashes, class_name)\n",
    "\n",
    "forest = forest.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Entropy acquisition function powered by the model to score project data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from encord_active.lib.common.active_learning import get_metric_results\n",
    "from encord_active.lib.metrics.acquisition_functions import Entropy\n",
    "from encord_active.lib.metrics.execute import execute_metrics\n",
    "\n",
    "acq_func = Entropy(w_model)\n",
    "\n",
    "# Run the acquisition function\n",
    "execute_metrics([acq_func], data_dir=project_fs.project_dir, use_cache_only=True)\n",
    "\n",
    "# Get the data scores\n",
    "acq_func_results = get_metric_results(project_fs, acq_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank and sample unlabelled data to label next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encord_active.lib.common.active_learning import get_n_best_ranked_data_samples\n",
    "\n",
    "data_to_label_next, scores = get_n_best_ranked_data_samples(\n",
    "    acq_func_results, \n",
    "    batch_size_to_label, \n",
    "    rank_by=\"desc\", \n",
    "    exclude_data_hashes=data_hashes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Visualize sampled data and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from encord_active.lib.common.active_learning import get_data_from_data_hashes\n",
    "\n",
    "image_paths, _ = get_data_from_data_hashes(project_fs, data_to_label_next, class_name)\n",
    "\n",
    "rows, cols = 10, 10\n",
    "fix, axs = plt.subplots(rows, cols, figsize=(10, 8))\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        index = i * cols + j\n",
    "        axs[i, j].imshow(mpimg.imread(image_paths[index]))\n",
    "        axs[i, j].set_title(round(scores[index], 2))\n",
    "        axs[i, j].axis('off')\n",
    "        \n",
    "plt.subplots_adjust(wspace=1.5, hspace=0.4)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
