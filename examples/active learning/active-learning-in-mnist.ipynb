{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from functools import partialmethod\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from loguru import logger\n",
    "from PIL import Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from encord_active.lib.common.iterator import DatasetIterator\n",
    "from encord_active.lib.metrics.execute import execute_metrics\n",
    "from encord_active.lib.project.project_file_structure import ProjectFileStructure\n",
    "\n",
    "# silence logger\n",
    "logger.remove()\n",
    "tqdm.__init__ = partialmethod(tqdm.__init__, disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_hashes_from_project(project_fs: ProjectFileStructure, subset_size=None):\n",
    "    iterator = DatasetIterator(project_fs.project_dir, subset_size)\n",
    "    data_hashes = [(iterator.label_hash, iterator.du_hash) for data_unit, img_pth in iterator.iterate()]\n",
    "    return data_hashes\n",
    "\n",
    "def get_data_from_data_hashes(project_fs: ProjectFileStructure, data_hashes: list[tuple[str, str]]):\n",
    "    image_arrays, class_labels = zip(*(get_data_sample(project_fs, data_hash) for data_hash in data_hashes))\n",
    "    return list(image_arrays), list(class_labels)\n",
    "\n",
    "def get_data_sample(project_fs: ProjectFileStructure, data_hash: tuple[str, str]):\n",
    "    label_hash, du_hash = data_hash\n",
    "    lr_struct = project_fs.label_row_structure(label_hash)\n",
    "    \n",
    "    # get classification label\n",
    "    label_row = json.loads(lr_struct.label_row_file.read_text())\n",
    "    class_label = get_classification_label(label_row, du_hash, class_name=\"digit\")\n",
    "    \n",
    "    # get image\n",
    "    image_path = lr_struct.images_dir / f\"{du_hash}.{label_row['data_units'][du_hash]['data_type'].split('/')[-1]}\"\n",
    "    image_array = np.asarray(Image.open(image_path)).flatten()\n",
    "    \n",
    "    return image_array, class_label\n",
    "\n",
    "def get_classification_label(label_row, du_hash: str, class_name: str):\n",
    "    data_unit = label_row[\"data_units\"][du_hash]\n",
    "    filtered_class = [_class for _class in data_unit[\"labels\"][\"classifications\"] if _class[\"name\"] == class_name]\n",
    "    if len(filtered_class) == 0:\n",
    "        return None\n",
    "    class_hash = filtered_class[0][\"classificationHash\"]\n",
    "    class_label = label_row[\"classification_answers\"][class_hash][\"classifications\"][0][\"answers\"]\n",
    "    return class_label\n",
    "\n",
    "def train_model(X_train, y_train, model=None):\n",
    "    # use logistic regression model as a dummy model example\n",
    "    if model is None:\n",
    "        model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def get_model_accuracy(X_test, y_test, model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def get_n_best_ranked_data_samples(project_fs: ProjectFileStructure, data_hashes, n, acq_func_instance, rank_by: str):\n",
    "    execute_metrics([acq_func_instance], data_dir=project_fs.project_dir)\n",
    "    unique_acq_func_name = acq_func_instance.metadata.get_unique_name()\n",
    "    acq_func_results = pd.read_csv(project_fs.metrics / f\"{unique_acq_func_name}.csv\")\n",
    "        \n",
    "    # filter acquisition function results to only contain data samples specified in data_hashes\n",
    "    str_data_hashes = tuple(f\"{label_hash}_{du_hash}\" for label_hash, du_hash in data_hashes)\n",
    "    filtered_results = acq_func_results[acq_func_results['identifier'].str.startswith(str_data_hashes, na=False)]\n",
    "    \n",
    "    if rank_by == \"asc\": # get the first n data samples if they were sorted by ascending score order\n",
    "        best_n = filtered_results[[\"identifier\", \"score\"]].nsmallest(n, \"score\", keep=\"first\")[\"identifier\"]\n",
    "    elif rank_by == \"desc\":  # get the first n data samples if they were sorted by descending score order\n",
    "        best_n = filtered_results[[\"identifier\", \"score\"]].nlargest(n, \"score\", keep=\"first\")[\"identifier\"]\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return [get_data_hash_from_identifier(identifier) for identifier in best_n]\n",
    "    \n",
    "def get_data_hash_from_identifier(identifier: str):\n",
    "    return tuple(identifier.split(\"_\", maxsplit=2)[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(Path(\"config.yaml\").read_text())[\"active-learning-in-mnist\"]\n",
    "\n",
    "# train\n",
    "project_dir_train = Path(config[\"train\"][\"project_dir\"])\n",
    "project_fs_train = ProjectFileStructure(project_dir_train)\n",
    "data_hashes_train = get_data_hashes_from_project(project_fs_train, subset_size=None)\n",
    "# shuffle data hashes\n",
    "data_hashes_train = shuffle(data_hashes_train, random_state=42)\n",
    "print(f\"Train dataset size: {len(data_hashes_train)}\")\n",
    "\n",
    "# test\n",
    "project_dir_test = Path(config[\"test\"][\"project_dir\"])\n",
    "project_fs_test = ProjectFileStructure(project_dir_test)\n",
    "data_hashes_test = get_data_hashes_from_project(project_fs_test)\n",
    "X_test, y_test = get_data_from_data_hashes(project_fs_test, data_hashes_test)\n",
    "print(f\"Test dataset size: {len(data_hashes_test)}\")\n",
    "\n",
    "# active learning (AL) config variables\n",
    "initial_data_amount = config[\"initial_data_amount\"]\n",
    "n_iterations = config[\"n_iterations\"]\n",
    "batch_size_to_label = config[\"batch_size_to_label\"]\n",
    "print(f\"Initial amount of labeled data in the train dataset: {initial_data_amount}\")\n",
    "print(f\"Number of iterations in the active learning (AL) workflow: {n_iterations}\")\n",
    "print(f\"Number of data samples annotated between AL iterations: {batch_size_to_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load acquisition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encord_active.lib.metrics.acquisition_functions import Entropy, LeastConfidence, Margin, Variance\n",
    "from encord_active.lib.metrics.heuristic.random import RandomImageMetric\n",
    "\n",
    "# use 'asc' (ascending) and 'desc' (descending) ordering for posterior selection of k highest ranked data samples\n",
    "acq_funcs = [\n",
    "    (Entropy, \"desc\"),\n",
    "    (LeastConfidence, \"desc\"),\n",
    "    (Margin, \"asc\"),\n",
    "    (Variance, \"asc\"),\n",
    "    (RandomImageMetric, \"asc\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the active learning workflow with each acquisition function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_logger = defaultdict(dict)\n",
    "for acq_func, rank_order in acq_funcs:\n",
    "    # mockup of the initial labeling phase\n",
    "    labeled_data_hashes_train = data_hashes_train[:initial_data_amount]\n",
    "    unlabeled_data_hashes_train = set(data_hashes_train[initial_data_amount:])\n",
    "    \n",
    "    X, y = get_data_from_data_hashes(project_fs_train, labeled_data_hashes_train)\n",
    "    model = train_model(X, y)\n",
    "    accuracy_logger[acq_func.__name__][0] = get_model_accuracy(X_test, y_test, model)\n",
    "    for it in tqdm(range(1, n_iterations + 1), disable=False, desc=f\"Analyzing {acq_func.__name__} performance\"):\n",
    "        if acq_func.__name__ in [\"RandomImageMetric\"]:\n",
    "            acq_func_instance = acq_func()\n",
    "        else:\n",
    "            acq_func_instance = acq_func(model)\n",
    "        data_to_label_next = get_n_best_ranked_data_samples(project_fs_train, unlabeled_data_hashes_train, batch_size_to_label, acq_func_instance, rank_by=rank_order)\n",
    "        \n",
    "        # mockup of the labeling phase\n",
    "        X_new, y_new = get_data_from_data_hashes(project_fs_train, data_to_label_next)\n",
    "        unlabeled_data_hashes_train.difference_update(data_to_label_next)\n",
    "        \n",
    "        X.extend(X_new)\n",
    "        y.extend(y_new)\n",
    "        model = train_model(X, y)\n",
    "        accuracy_logger[acq_func.__name__][it] = get_model_accuracy(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misc: beautify function names\n",
    "if RandomImageMetric.__name__ in accuracy_logger:\n",
    "    accuracy_logger[\"Random\"] = accuracy_logger.pop(RandomImageMetric.__name__)\n",
    "if LeastConfidence.__name__ in accuracy_logger:\n",
    "    accuracy_logger[\"Least Confidence\"] = accuracy_logger.pop(LeastConfidence.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show results of the active learning workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for acq_func_name, points in accuracy_logger.items():\n",
    "    xs, ys = zip(*points.items())\n",
    "    plt.plot(xs, ys, label=acq_func_name)\n",
    "\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Model Accuracy\")\n",
    "plt.xticks(range(n_iterations + 1))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
