{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the most difficult images to label next\n",
    "\n",
    "*This notebook shows you how to plug your ML model in Encord Active to rank the images according to an acquisition function.\n",
    "We assume that you already have installed encord-active in your local environment, if not please visit [here](https://docs.encord.com/active/docs/installation).*\n",
    "\n",
    "### The  Motivation\n",
    "\n",
    "Let's say you have an image dataset consist of different airplanes. You want to train an object detector model to get the bounding boxes of the planes and later crop those regions to create a collage of airplanes pictures for yourself.\n",
    "[Here](https://storage.googleapis.com/encord-active-notebook-demos/airplanes-active-learning-demo.zip), we have an Encord Active project like this. Download the zipped folder, extract it, and run encord active in the project folder or its parent folder to visualize this project.\n",
    "\n",
    "To start the Encord-Active app, run the following command:\n",
    "`encord-active visualize`\n",
    "\n",
    "You can visualize the images according to certain image-level metrics in the Data Quality -> Explorer page.\n",
    "\n",
    "There are 799 images in the dataset; however, you do not want to label all of them, which would be quite cumbersome. You only want to label 50 images and you want to select the best 50 images that will give you the best outcome in terms of model performance.\n",
    "\n",
    "In an active learning workflow, you generally have a model trained on a few initial labeled samples. In this notebook, for the simplicity, we will use a HuggingFace YOLOS-tiny model that is trained on COCO dataset, in which there is an `airplane` class! So, we will use the YOLOS-tiny model's output for the `airplane` class to rank the images.\n",
    "\n",
    "As an acquisition function, you will use Encord Active's `AverageFrameScore`. This acquisition function gets the average confidence scores of the predictions in each image, if there is no prediction, it assigns zero. You think that in all of your images there is at least one airplane, so this acquisition function is very suitable for your task. If the score is low, model is having difficulty in detecting airplanes in those images, so you may want to collect these samples to label next.\n",
    "\n",
    "Let's start, you will see how easy to do that with Encord Active!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install the Huggingface transformer library for the object detecion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ea_examples/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "from PIL import Image\n",
    "from transformers import YolosImageProcessor, YolosForObjectDetection\n",
    "import torch\n",
    "from encord_active.lib.metrics.acquisition_metrics.object_level_acquisition_functions import (\n",
    "    AverageFrameScore,\n",
    "    BaseObjectModel,\n",
    "    BoundingBoxPrediction,\n",
    ")\n",
    "from encord_active.lib.metrics.execute import execute_metrics\n",
    "from encord_active.lib.project.project_file_structure import ProjectFileStructure\n",
    "from encord_active.lib.metrics.metadata import fetch_metrics_meta\n",
    "from encord_active.lib.metrics.io import  get_metric_metadata\n",
    "from encord_active.lib.metrics.metadata import update_metrics_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement a BaseBoundingBoxModelWrapper class\n",
    "\n",
    "This class will inherit the `BaseBoundingBoxModelWrapper` class and only  implement the `predict_boundingboxes()` method, where a Pillow's Image is taken as an argument and list of bounding boxes will be returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HuggingFaceYolosTinyModel(BaseObjectModel):\n",
    "    \"\"\"\n",
    "    For more information on how to use this model, check here: https://huggingface.co/hustvl/yolos-tiny\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.processor = YolosImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "        self.model = YolosForObjectDetection.from_pretrained('hustvl/yolos-tiny')\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_objects(self, image: Image)-> List[BoundingBoxPrediction]:\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "\n",
    "        data = self.processor(images=image, return_tensors=\"pt\")\n",
    "        outputs = self.model(**data)\n",
    "\n",
    "        target_sizes = torch.tensor([image.size[::-1]])\n",
    "        results = self.processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.5)[0]\n",
    "\n",
    "        output: List[BoundingBoxPrediction] = []\n",
    "        for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "            if label == 5: # id 5 corresponds to 'airplane' class in COCO Dataset\n",
    "                box = box.numpy()\n",
    "                output.append(BoundingBoxPrediction(x=box[0], y=box[1], w=box[2]-box[0], h=box[3]-box[1], confidence=score.item()))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the acquisition metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 09:07:33.797 | INFO     | encord_active.lib.metrics.execute:_execute_metrics:129 - Running metric Average Frame Score\n",
      "                                                                           \r"
     ]
    }
   ],
   "source": [
    "project_fs = ProjectFileStructure(Path(\"/path/to/encord-active/project\"))\n",
    "\n",
    "# Create the acquisition metric\n",
    "acq_func = AverageFrameScore(HuggingFaceYolosTinyModel())\n",
    "\n",
    "# Run the acquisition metric\n",
    "execute_metrics([acq_func], data_dir=project_fs.project_dir, use_cache_only=True)\n",
    "\n",
    "# Update the metric files\n",
    "metrics_meta = fetch_metrics_meta(project_fs)\n",
    "metrics_meta[acq_func.metadata.title]= get_metric_metadata(acq_func)\n",
    "update_metrics_meta(project_fs, metrics_meta)\n",
    "\n",
    "project_fs.db.unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Next steps\n",
    "\n",
    "Now, we have run our acquisition function on all samples. When you open the project from the start, you will see this new acquisition metric in the Data Quality Explorer page. Click the arrow in the metrics dropdown list and select 'Average Frame Score'. The images that have a score of zero represents that your current model is missing the airplanes in these examples and low scores mean that model is not confident in its predictions, so they should have higher priority when labelling. As a next step you have several options now; you can select the first N samples and:\n",
    "\n",
    "1. create a new project on Encord Annotate platform to label.\n",
    "2. export them using the Actions tab and use them in your own annotation tool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
